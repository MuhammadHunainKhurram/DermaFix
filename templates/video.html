<style>
  body {
    background-color: #89cff0;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    height: 100vh;
    font-family: "Courier New";
  }

  h1 {
    font-size: 48px;
    color: #333; /* Text color */
    font-weight: bolder;
    -webkit-text-stroke: 2px #333; /* Add a 2px white outline (adjust as needed) */
    -webkit-text-fill-color: white; /* Text color */
  }

  button {
    display: inline-block;
    padding: 10px 20px;
    font-size: 36px;
    background-color: white;
    color: #89cff0; /* Text color */
    border: 2px solid black; /* Border color and width */
    border-radius: 10px; /* Rounded corners */
    text-align: center;
    text-decoration: none; /* Remove underlines */
    cursor: pointer;
    transition: background-color 0.3s, color 0.3s, border-color 0.3s; /* Smooth transitions */
    -webkit-text-stroke: 2px #333; /* Add a 2px white outline (adjust as needed) */
    -webkit-text-fill-color: white; /* Text color */
  }

  button:hover {
    background-color: #89cff0;
    color: white;
  }
</style>

<h1>Live Video Consultation</h1>
<button type="button" onclick="init()">Start</button>

<div id="webcam-container"></div>
<div id="label-container"></div>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
<script type="text/javascript">
  // More API functions here:
  // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

  // the link to your model provided by Teachable Machine export panel
  const URL = "https://teachablemachine.withgoogle.com/models/rtbRb3JLQ/";

  let model, webcam, labelContainer, maxPredictions;

  // Load the image model and setup the webcam
  async function init() {
    const modelURL = URL + "model.json";
    const metadataURL = URL + "metadata.json";

    // load the model and metadata
    // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
    // or files from your local hard drive
    // Note: the pose library adds "tmImage" object to your window (window.tmImage)
    model = await tmImage.load(modelURL, metadataURL);
    maxPredictions = model.getTotalClasses();

    // Convenience function to setup a webcam
    const flip = true; // whether to flip the webcam
    webcam = new tmImage.Webcam(500, 500, flip); // width, height, flip
    await webcam.setup(); // request access to the webcam
    await webcam.play();
    window.requestAnimationFrame(loop);

    // append elements to the DOM
    document.getElementById("webcam-container").appendChild(webcam.canvas);
    labelContainer = document.getElementById("label-container");
    for (let i = 0; i < maxPredictions; i++) {
      // and class labels
      labelContainer.appendChild(document.createElement("div"));
    }
  }

  async function loop() {
    webcam.update(); // update the webcam frame
    await predict();
    window.requestAnimationFrame(loop);
  }

  async function predict() {
    // predict can take in an image, video or canvas html element
    const prediction = await model.predict(webcam.canvas);
    let maxValue = prediction[0].probability.toFixed(2); // Initialize maxValue with the first element
    let maxIndex = 0;
    let amount = 0;
    for (let i = 0; i < maxPredictions; i++) {
      if (prediction[i].probability.toFixed(2) > maxValue) {
        maxValue = prediction[i].probability.toFixed(2); // Update maxValue if a larger value is found
        maxIndex = prediction[i].className;
      }
      const classPrediction =
        " Likely Diagnosed with: " +
        prediction[i].className +
        " Chance: " +
        prediction[i].probability.toFixed(2);
      if (prediction[i].probability.toFixed(2) != 0 && amount <= 2) {
        labelContainer.childNodes[i].innerHTML = classPrediction;
        amount++;
      } else {
        labelContainer.childNodes[i].innerHTML = "";
      }
    }
  }
</script>
